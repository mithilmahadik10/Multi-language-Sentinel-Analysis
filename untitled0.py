# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HMgeH-nYKc6McpuVBXaOkGibrV7DI5vD
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import re
import string
import nltk
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import joblib

# Download necessary resources
nltk.download('stopwords')

# Load dataset
file_path = '/content/multi_language_sentiment_50.xlsx'
df = pd.read_excel(file_path)

# Ensure necessary columns exist
if 'Text' not in df.columns or 'Emotion' not in df.columns:
    raise ValueError("Dataset must contain 'Text' and 'Emotion' columns")

# Preprocessing function
def preprocess_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower()  # Convert to lowercase
    text = re.sub(f"[{string.punctuation}]", "", text)  # Remove punctuation
    text = re.sub(r'\d+', '', text)  # Remove numbers
    stop_words = set(stopwords.words('english'))
    words = text.split()
    words = [word for word in words if word not in stop_words]  # Remove stopwords
    return ' '.join(words)

# Apply preprocessing
df['Cleaned_Text'] = df['Text'].astype(str).apply(preprocess_text)

# Encode labels
df['Emotion_Label'] = df['Emotion'].astype('category').cat.codes

# Check if dataset is sufficient for training
if df['Cleaned_Text'].nunique() < 2 or df['Emotion_Label'].nunique() < 2:
    raise ValueError("Dataset must have at least two unique texts and labels")

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    df['Cleaned_Text'], df['Emotion_Label'], test_size=0.2, random_state=42, stratify=df['Emotion_Label']
)

# Convert text to numerical features
vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Train model
model = LogisticRegression(max_iter=500)
model.fit(X_train_tfidf, y_train)

# Predictions
y_pred = model.predict(X_test_tfidf)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
print("Model Accuracy:", accuracy)
print("Classification Report:\n", classification_report(y_test, y_pred, zero_division=0))

# Calculate percentage of each sentiment
emotion_counts = df['Emotion'].value_counts(normalize=True) * 100
print("Sentiment Distribution (%):\n", emotion_counts)

# Save model and vectorizer
joblib.dump(model, "sentiment_model.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")